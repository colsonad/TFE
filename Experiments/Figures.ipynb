{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_mean_001train_loss = np.load(\"gd_mean_001\"+\"train_loss.npy\")\n",
    "gd_mean_001test_loss = np.load(\"gd_mean_001\"+\"test_loss.npy\")\n",
    "gd_mean_001norm = np.load(\"gd_mean_001\"+\"norm.npy\")\n",
    "gd_mean_001train_accuracy = np.load(\"gd_mean_001\"+\"train_accuracy.npy\")\n",
    "gd_mean_001test_accuracy = np.load(\"gd_mean_001\"+\"test_accuracy.npy\")\n",
    "\n",
    "train_loss_mean_001 = np.mean(gd_mean_001train_loss, axis=0)\n",
    "test_loss_mean_001 = np.mean(gd_mean_001test_loss, axis=0)\n",
    "norm_mean_001 = np.mean(gd_mean_001norm, axis=0)\n",
    "train_accuracy_mean_001 = np.mean(gd_mean_001train_accuracy, axis=0)\n",
    "test_accuracy_mean_001 = np.mean(gd_mean_001test_accuracy, axis=0)\n",
    "\n",
    "print(\"Final test accuracy mean: \", test_accuracy_mean_001[-1])\n",
    "print(\"Final test accuracy max: \", np.max(gd_mean_001test_accuracy[:, -1]))\n",
    "\n",
    "print(\"Final train loss mean: \", train_loss_mean_001[-1])\n",
    "print(\"Final train loss max: \", np.max(gd_mean_001train_loss[:, -1]))\n",
    "\n",
    "print(\"Final norm mean: \", norm_mean_001[-1])\n",
    "print(\"Final norm max: \", np.max(gd_mean_001norm[:, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_mean_001_a4atrain_loss = np.load(\"gd_mean_001_a4a\"+\"train_loss.npy\")\n",
    "gd_mean_001_a4atest_loss = np.load(\"gd_mean_001_a4a\"+\"test_loss.npy\")\n",
    "gd_mean_001_a4anorm = np.load(\"gd_mean_001_a4a\"+\"norm.npy\")\n",
    "gd_mean_001_a4atrain_accuracy = np.load(\"gd_mean_001_a4a\"+\"train_accuracy.npy\")\n",
    "gd_mean_001_a4atest_accuracy = np.load(\"gd_mean_001_a4a\"+\"test_accuracy.npy\")\n",
    "\n",
    "train_loss_mean_001_a4a = np.mean(gd_mean_001_a4atrain_loss, axis=0)\n",
    "test_loss_mean_001_a4a = np.mean(gd_mean_001_a4atest_loss, axis=0)\n",
    "norm_mean_001_a4a = np.mean(gd_mean_001_a4anorm, axis=0)\n",
    "train_accuracy_mean_001_a4a = np.mean(gd_mean_001_a4atrain_accuracy, axis=0)\n",
    "test_accuracy_mean_001_a4a = np.mean(gd_mean_001_a4atest_accuracy, axis=0)\n",
    "\n",
    "print(\"Final test accuracy mean: \", test_accuracy_mean_001_a4a[-1])\n",
    "print(\"Final test accuracy max: \", np.max(gd_mean_001_a4atest_accuracy[:, -1]))\n",
    "\n",
    "print(\"Final train loss mean: \", train_loss_mean_001_a4a[-1])\n",
    "print(\"Final train loss max: \", np.max(gd_mean_001_a4atrain_loss[:, -1]))\n",
    "\n",
    "print(\"Final norm mean: \", norm_mean_001_a4a[-1])\n",
    "print(\"Final norm max: \", np.max(gd_mean_001_a4anorm[:, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_mean_0005train_loss = np.load(\"gd_mean_0005\"+\"train_loss.npy\")\n",
    "gd_mean_0005test_loss = np.load(\"gd_mean_0005\"+\"test_loss.npy\")\n",
    "gd_mean_0005norm = np.load(\"gd_mean_0005\"+\"norm.npy\")\n",
    "gd_mean_0005train_accuracy = np.load(\"gd_mean_0005\"+\"train_accuracy.npy\")\n",
    "gd_mean_0005test_accuracy = np.load(\"gd_mean_0005\"+\"test_accuracy.npy\")\n",
    "\n",
    "train_loss_mean_0005 = np.mean(gd_mean_0005train_loss, axis=0)\n",
    "test_loss_mean_0005 = np.mean(gd_mean_0005test_loss, axis=0)\n",
    "norm_mean_0005 = np.mean(gd_mean_0005norm, axis=0)\n",
    "train_accuracy_mean_0005 = np.mean(gd_mean_0005train_accuracy, axis=0)\n",
    "test_accuracy_mean_0005 = np.mean(gd_mean_0005test_accuracy, axis=0)\n",
    "\n",
    "print(\"Final test accuracy mean: \", test_accuracy_mean_0005[-1])\n",
    "print(\"Final test accuracy max: \", np.max(gd_mean_0005test_accuracy[:, -1]))\n",
    "\n",
    "print(\"Final train loss mean: \", train_loss_mean_0005[-1])\n",
    "print(\"Final train loss max: \", np.max(gd_mean_0005train_loss[:, -1]))\n",
    "\n",
    "print(\"Final norm mean: \", norm_mean_0005[-1])\n",
    "print(\"Final norm max: \", np.max(gd_mean_0005norm[:, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_mean_0005_a4atrain_loss = np.load(\"gd_mean_0005_a4a\"+\"train_loss.npy\")\n",
    "gd_mean_0005_a4atest_loss = np.load(\"gd_mean_0005_a4a\"+\"test_loss.npy\")\n",
    "gd_mean_0005_a4anorm = np.load(\"gd_mean_0005_a4a\"+\"norm.npy\")\n",
    "gd_mean_0005_a4atrain_accuracy = np.load(\"gd_mean_0005_a4a\"+\"train_accuracy.npy\")\n",
    "gd_mean_0005_a4atest_accuracy = np.load(\"gd_mean_0005_a4a\"+\"test_accuracy.npy\")\n",
    "\n",
    "train_loss_mean_0005_a4a = np.mean(gd_mean_0005_a4atrain_loss, axis=0)\n",
    "test_loss_mean_0005_a4a = np.mean(gd_mean_0005_a4atest_loss, axis=0)\n",
    "norm_mean_0005_a4a = np.mean(gd_mean_0005_a4anorm, axis=0)\n",
    "train_accuracy_mean_0005_a4a = np.mean(gd_mean_0005_a4atrain_accuracy, axis=0)\n",
    "test_accuracy_mean_0005_a4a = np.mean(gd_mean_0005_a4atest_accuracy, axis=0)\n",
    "\n",
    "print(\"Final test accuracy mean: \", test_accuracy_mean_0005_a4a[-1])\n",
    "print(\"Final test accuracy max: \", np.max(gd_mean_0005_a4atest_accuracy[:, -1]))\n",
    "\n",
    "print(\"Final train loss mean: \", train_loss_mean_0005_a4a[-1])\n",
    "print(\"Final train loss max: \", np.max(gd_mean_0005_a4atrain_loss[:, -1]))\n",
    "\n",
    "print(\"Final norm mean: \", norm_mean_0005_a4a[-1])\n",
    "print(\"Final norm max: \", np.max(gd_mean_0005_a4anorm[:, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_001train_loss_1 = np.load(\"gd_001\"+\"train_loss_1.npy\")\n",
    "gd_001test_loss_1 = np.load(\"gd_001\"+\"test_loss_1.npy\")\n",
    "gd_001norm_1 = np.load(\"gd_001\"+\"norm_1.npy\")\n",
    "gd_001train_accuracy_1 = np.load(\"gd_001\"+\"train_accuracy_1.npy\")\n",
    "gd_001test_accuracy_1 = np.load(\"gd_001\"+\"test_accuracy_1.npy\")\n",
    "\n",
    "gd_001train_loss_15 = np.load(\"gd_001\"+\"train_loss_15.npy\")\n",
    "gd_001test_loss_15 = np.load(\"gd_001\"+\"test_loss_15.npy\")\n",
    "gd_001norm_15 = np.load(\"gd_001\"+\"norm_15.npy\")\n",
    "gd_001train_accuracy_15 = np.load(\"gd_001\"+\"train_accuracy_15.npy\")\n",
    "gd_001test_accuracy_15 = np.load(\"gd_001\"+\"test_accuracy_15.npy\")\n",
    "\n",
    "gd_001train_loss_2 = np.load(\"gd_001\"+\"train_loss_2.npy\")\n",
    "gd_001test_loss_2 = np.load(\"gd_001\"+\"test_loss_2.npy\")\n",
    "gd_001norm_2 = np.load(\"gd_001\"+\"norm_2.npy\")\n",
    "gd_001train_accuracy_2 = np.load(\"gd_001\"+\"train_accuracy_2.npy\")\n",
    "gd_001test_accuracy_2 = np.load(\"gd_001\"+\"test_accuracy_2.npy\")\n",
    "\n",
    "print(\"Final test accuracy 1/L: \", gd_001test_accuracy_1[-1])\n",
    "print(\"Final test accuracy 1.5/L: \", gd_001test_accuracy_15[-1])\n",
    "print(\"Final test accuracy 2/L: \", gd_001test_accuracy_2[-1])\n",
    "\n",
    "print(\"Final train loss 1/L: \", gd_001train_loss_1[-1])\n",
    "print(\"Final train loss 1.5/L: \", gd_001train_loss_15[-1])\n",
    "print(\"Final train loss 2/L: \", gd_001train_loss_2[-1])\n",
    "\n",
    "print(\"Final norm 1/L: \", gd_001norm_1[-1])\n",
    "print(\"Final norm 1.5/L: \", gd_001norm_15[-1])\n",
    "print(\"Final norm 2/L: \", gd_001norm_2[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_001_a4atrain_loss_1 = np.load(\"gd_001_a4a\"+\"train_loss_1.npy\")\n",
    "gd_001_a4atest_loss_1 = np.load(\"gd_001_a4a\"+\"test_loss_1.npy\")\n",
    "gd_001_a4anorm_1 = np.load(\"gd_001_a4a\"+\"norm_1.npy\")\n",
    "gd_001_a4atrain_accuracy_1 = np.load(\"gd_001_a4a\"+\"train_accuracy_1.npy\")\n",
    "gd_001_a4atest_accuracy_1 = np.load(\"gd_001_a4a\"+\"test_accuracy_1.npy\")\n",
    "\n",
    "gd_001_a4atrain_loss_15 = np.load(\"gd_001_a4a\"+\"train_loss_15.npy\")\n",
    "gd_001_a4atest_loss_15 = np.load(\"gd_001_a4a\"+\"test_loss_15.npy\")\n",
    "gd_001_a4anorm_15 = np.load(\"gd_001_a4a\"+\"norm_15.npy\")\n",
    "gd_001_a4atrain_accuracy_15 = np.load(\"gd_001_a4a\"+\"train_accuracy_15.npy\")\n",
    "gd_001_a4atest_accuracy_15 = np.load(\"gd_001_a4a\"+\"test_accuracy_15.npy\")\n",
    "\n",
    "gd_001_a4atrain_loss_2 = np.load(\"gd_001_a4a\"+\"train_loss_2.npy\")\n",
    "gd_001_a4atest_loss_2 = np.load(\"gd_001_a4a\"+\"test_loss_2.npy\")\n",
    "gd_001_a4anorm_2 = np.load(\"gd_001_a4a\"+\"norm_2.npy\")\n",
    "gd_001_a4atrain_accuracy_2 = np.load(\"gd_001_a4a\"+\"train_accuracy_2.npy\")\n",
    "gd_001_a4atest_accuracy_2 = np.load(\"gd_001_a4a\"+\"test_accuracy_2.npy\")\n",
    "\n",
    "print(\"Final test accuracy 1/L: \", gd_001_a4atest_accuracy_1[-1])\n",
    "print(\"Final test accuracy 1.5/L: \", gd_001_a4atest_accuracy_15[-1])\n",
    "print(\"Final test accuracy 2/L: \", gd_001_a4atest_accuracy_2[-1])\n",
    "\n",
    "print(\"Final train loss 1/L: \", gd_001_a4atrain_loss_1[-1])\n",
    "print(\"Final train loss 1.5/L: \", gd_001_a4atrain_loss_15[-1])\n",
    "print(\"Final train loss 2/L: \", gd_001_a4atrain_loss_2[-1])\n",
    "\n",
    "print(\"Final norm 1/L: \", gd_001_a4anorm_1[-1])\n",
    "print(\"Final norm 1.5/L: \", gd_001_a4anorm_15[-1])\n",
    "print(\"Final norm 2/L: \", gd_001_a4anorm_2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_0005train_loss_1 = np.load(\"gd_0005\"+\"train_loss_1.npy\")\n",
    "gd_0005test_loss_1 = np.load(\"gd_0005\"+\"test_loss_1.npy\")\n",
    "gd_0005norm_1 = np.load(\"gd_0005\"+\"norm_1.npy\")\n",
    "gd_0005train_accuracy_1 = np.load(\"gd_0005\"+\"train_accuracy_1.npy\")\n",
    "gd_0005test_accuracy_1 = np.load(\"gd_0005\"+\"test_accuracy_1.npy\")\n",
    "\n",
    "gd_0005train_loss_15 = np.load(\"gd_0005\"+\"train_loss_15.npy\")\n",
    "gd_0005test_loss_15 = np.load(\"gd_0005\"+\"test_loss_15.npy\")\n",
    "gd_0005norm_15 = np.load(\"gd_0005\"+\"norm_15.npy\")\n",
    "gd_0005train_accuracy_15 = np.load(\"gd_0005\"+\"train_accuracy_15.npy\")\n",
    "gd_0005test_accuracy_15 = np.load(\"gd_0005\"+\"test_accuracy_15.npy\")\n",
    "\n",
    "gd_0005train_loss_2 = np.load(\"gd_0005\"+\"train_loss_2.npy\")\n",
    "gd_0005test_loss_2 = np.load(\"gd_0005\"+\"test_loss_2.npy\")\n",
    "gd_0005norm_2 = np.load(\"gd_0005\"+\"norm_2.npy\")\n",
    "gd_0005train_accuracy_2 = np.load(\"gd_0005\"+\"train_accuracy_2.npy\")\n",
    "gd_0005test_accuracy_2 = np.load(\"gd_0005\"+\"test_accuracy_2.npy\")\n",
    "\n",
    "print(\"Final test accuracy 1/L: \", gd_0005test_accuracy_1[-1])\n",
    "print(\"Final test accuracy 1.5/L: \", gd_0005test_accuracy_15[-1])\n",
    "print(\"Final test accuracy 2/L: \", gd_0005test_accuracy_2[-1])\n",
    "\n",
    "print(\"Final train loss 1/L: \", gd_0005train_loss_1[-1])\n",
    "print(\"Final train loss 1.5/L: \", gd_0005train_loss_15[-1])\n",
    "print(\"Final train loss 2/L: \", gd_0005train_loss_2[-1])\n",
    "\n",
    "print(\"Final norm 1/L: \", gd_0005norm_1[-1])\n",
    "print(\"Final norm 1.5/L: \", gd_0005norm_15[-1])\n",
    "print(\"Final norm 2/L: \", gd_0005norm_2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_0005_a4atrain_loss_1 = np.load(\"gd_0005_a4a\"+\"train_loss_1.npy\")\n",
    "gd_0005_a4atest_loss_1 = np.load(\"gd_0005_a4a\"+\"test_loss_1.npy\")\n",
    "gd_0005_a4anorm_1 = np.load(\"gd_0005_a4a\"+\"norm_1.npy\")\n",
    "gd_0005_a4atrain_accuracy_1 = np.load(\"gd_0005_a4a\"+\"train_accuracy_1.npy\")\n",
    "gd_0005_a4atest_accuracy_1 = np.load(\"gd_0005_a4a\"+\"test_accuracy_1.npy\")\n",
    "\n",
    "gd_0005_a4atrain_loss_15 = np.load(\"gd_0005_a4a\"+\"train_loss_15.npy\")\n",
    "gd_0005_a4atest_loss_15 = np.load(\"gd_0005_a4a\"+\"test_loss_15.npy\")\n",
    "gd_0005_a4anorm_15 = np.load(\"gd_0005_a4a\"+\"norm_15.npy\")\n",
    "gd_0005_a4atrain_accuracy_15 = np.load(\"gd_0005_a4a\"+\"train_accuracy_15.npy\")\n",
    "gd_0005_a4atest_accuracy_15 = np.load(\"gd_0005_a4a\"+\"test_accuracy_15.npy\")\n",
    "\n",
    "gd_0005_a4atrain_loss_2 = np.load(\"gd_0005_a4a\"+\"train_loss_2.npy\")\n",
    "gd_0005_a4atest_loss_2 = np.load(\"gd_0005_a4a\"+\"test_loss_2.npy\")\n",
    "gd_0005_a4anorm_2 = np.load(\"gd_0005_a4a\"+\"norm_2.npy\")\n",
    "gd_0005_a4atrain_accuracy_2 = np.load(\"gd_0005_a4a\"+\"train_accuracy_2.npy\")\n",
    "gd_0005_a4atest_accuracy_2 = np.load(\"gd_0005_a4a\"+\"test_accuracy_2.npy\")\n",
    "\n",
    "print(\"Final test accuracy 1/L: \", gd_0005_a4atest_accuracy_1[-1])\n",
    "print(\"Final test accuracy 1.5/L: \", gd_0005_a4atest_accuracy_15[-1])\n",
    "print(\"Final test accuracy 2/L: \", gd_0005_a4atest_accuracy_2[-1])\n",
    "\n",
    "print(\"Final train loss 1/L: \", gd_0005_a4atrain_loss_1[-1])\n",
    "print(\"Final train loss 1.5/L: \", gd_0005_a4atrain_loss_15[-1])\n",
    "print(\"Final train loss 2/L: \", gd_0005_a4atrain_loss_2[-1])\n",
    "\n",
    "print(\"Final norm 1/L: \", gd_0005_a4anorm_1[-1])\n",
    "print(\"Final norm 1.5/L: \", gd_0005_a4anorm_15[-1])\n",
    "print(\"Final norm 2/L: \", gd_0005_a4anorm_2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_001train_loss = np.load(\"dynamic_001\"+\"train_loss.npy\")\n",
    "dynamic_001test_loss = np.load(\"dynamic_001\"+\"test_loss.npy\")\n",
    "dynamic_001norm = np.load(\"dynamic_001\"+\"norm.npy\")\n",
    "dynamic_001train_accuracy  = np.load(\"dynamic_001\"+\"train_accuracy.npy\")\n",
    "dynamic_001test_accuracy  = np.load(\"dynamic_001\"+\"test_accuracy.npy\")\n",
    "dynamic_001stepsizes = np.load(\"dynamic_001\"+\"stepsizes.npy\")\n",
    "\n",
    "print(\"Final test accuracy : \", dynamic_001test_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", dynamic_001train_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", dynamic_001norm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_001_a4atrain_loss = np.load(\"dynamic_001_a4a\"+\"train_loss.npy\")\n",
    "dynamic_001_a4atest_loss = np.load(\"dynamic_001_a4a\"+\"test_loss.npy\")\n",
    "dynamic_001_a4anorm = np.load(\"dynamic_001_a4a\"+\"norm.npy\")\n",
    "dynamic_001_a4atrain_accuracy  = np.load(\"dynamic_001_a4a\"+\"train_accuracy.npy\")\n",
    "dynamic_001_a4atest_accuracy  = np.load(\"dynamic_001_a4a\"+\"test_accuracy.npy\")\n",
    "dynamic_001_a4astepsizes = np.load(\"dynamic_001_a4a\"+\"stepsizes.npy\")\n",
    "\n",
    "print(\"Final test accuracy : \", dynamic_001_a4atest_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", dynamic_001_a4atrain_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", dynamic_001_a4anorm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_0005train_loss = np.load(\"dynamic_0005\"+\"train_loss.npy\")\n",
    "dynamic_0005test_loss = np.load(\"dynamic_0005\"+\"test_loss.npy\")\n",
    "dynamic_0005norm = np.load(\"dynamic_0005\"+\"norm.npy\")\n",
    "dynamic_0005train_accuracy  = np.load(\"dynamic_0005\"+\"train_accuracy.npy\")\n",
    "dynamic_0005test_accuracy  = np.load(\"dynamic_0005\"+\"test_accuracy.npy\")\n",
    "dynamic_0005stepsizes = np.load(\"dynamic_0005\"+\"stepsizes.npy\")\n",
    "\n",
    "print(\"Final test accuracy : \", dynamic_0005test_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", dynamic_0005train_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", dynamic_0005norm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_0005_a4atrain_loss = np.load(\"dynamic_0005_a4a\"+\"train_loss.npy\")\n",
    "dynamic_0005_a4atest_loss = np.load(\"dynamic_0005_a4a\"+\"test_loss.npy\")\n",
    "dynamic_0005_a4anorm = np.load(\"dynamic_0005_a4a\"+\"norm.npy\")\n",
    "dynamic_0005_a4atrain_accuracy  = np.load(\"dynamic_0005_a4a\"+\"train_accuracy.npy\")\n",
    "dynamic_0005_a4atest_accuracy  = np.load(\"dynamic_0005_a4a\"+\"test_accuracy.npy\")\n",
    "dynamic_0005_a4astepsizes = np.load(\"dynamic_0005_a4a\"+\"stepsizes.npy\")\n",
    "\n",
    "print(\"Final test accuracy : \", dynamic_0005_a4atest_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", dynamic_0005_a4atrain_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", dynamic_0005_a4anorm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_001train_loss = np.load(\"optimal_001\"+\"train_loss.npy\")\n",
    "optimal_001test_loss = np.load(\"optimal_001\"+\"test_loss.npy\")\n",
    "optimal_001norm = np.load(\"optimal_001\"+\"norm.npy\")\n",
    "optimal_001train_accuracy  = np.load(\"optimal_001\"+\"train_accuracy.npy\")\n",
    "optimal_001test_accuracy  = np.load(\"optimal_001\"+\"test_accuracy.npy\")\n",
    "optimal_001stepsizes = np.load(\"optimal_001\"+\"stepsizes.npy\")\n",
    "\n",
    "print(\"Final test accuracy : \", optimal_001test_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", optimal_001train_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", optimal_001norm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_001_a4atrain_loss = np.load(\"optimal_001_a4a\"+\"train_loss.npy\")\n",
    "optimal_001_a4atest_loss = np.load(\"optimal_001_a4a\"+\"test_loss.npy\")\n",
    "optimal_001_a4anorm = np.load(\"optimal_001_a4a\"+\"norm.npy\")\n",
    "optimal_001_a4atrain_accuracy  = np.load(\"optimal_001_a4a\"+\"train_accuracy.npy\")\n",
    "optimal_001_a4atest_accuracy  = np.load(\"optimal_001_a4a\"+\"test_accuracy.npy\")\n",
    "optimal_001_a4astepsizes = np.load(\"optimal_001_a4a\"+\"stepsizes.npy\")\n",
    "\n",
    "print(\"Final test accuracy : \", optimal_001_a4atest_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", optimal_001_a4atrain_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", optimal_001_a4anorm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_0005train_loss = np.load(\"optimal_0005\"+\"train_loss.npy\")\n",
    "optimal_0005test_loss = np.load(\"optimal_0005\"+\"test_loss.npy\")\n",
    "optimal_0005norm = np.load(\"optimal_0005\"+\"norm.npy\")\n",
    "optimal_0005train_accuracy  = np.load(\"optimal_0005\"+\"train_accuracy.npy\")\n",
    "optimal_0005test_accuracy  = np.load(\"optimal_0005\"+\"test_accuracy.npy\")\n",
    "optimal_0005stepsizes = np.load(\"optimal_0005\"+\"stepsizes.npy\")\n",
    "\n",
    "print(\"Final test accuracy : \", optimal_0005test_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", optimal_0005train_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", optimal_0005norm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_0005_a4atrain_loss = np.load(\"optimal_0005_a4a\"+\"train_loss.npy\")\n",
    "optimal_0005_a4atest_loss = np.load(\"optimal_0005_a4a\"+\"test_loss.npy\")\n",
    "optimal_0005_a4anorm = np.load(\"optimal_0005_a4a\"+\"norm.npy\")\n",
    "optimal_0005_a4atrain_accuracy  = np.load(\"optimal_0005_a4a\"+\"train_accuracy.npy\")\n",
    "optimal_0005_a4atest_accuracy  = np.load(\"optimal_0005_a4a\"+\"test_accuracy.npy\")\n",
    "optimal_0005_a4astepsizes = np.load(\"optimal_0005_a4a\"+\"stepsizes.npy\")\n",
    "\n",
    "print(\"Final test accuracy : \", optimal_0005_a4atest_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", optimal_0005_a4atrain_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", optimal_0005_a4anorm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_001train_loss = np.load(\"exact_001\"+\"train_loss.npy\")\n",
    "exact_001test_loss = np.load(\"exact_001\"+\"test_loss.npy\")\n",
    "exact_001norm = np.load(\"exact_001\"+\"norm.npy\")\n",
    "exact_001train_accuracy  = np.load(\"exact_001\"+\"train_accuracy.npy\")\n",
    "exact_001test_accuracy  = np.load(\"exact_001\"+\"test_accuracy.npy\")\n",
    "exact_001stepsizes = np.load(\"exact_001\"+\"stepsizes.npy\")\n",
    "\n",
    "print(\"Final test accuracy : \", exact_001test_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", exact_001train_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", exact_001norm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_001_a4atrain_loss = np.load(\"exact_001_a4a\"+\"train_loss.npy\")\n",
    "exact_001_a4atest_loss = np.load(\"exact_001_a4a\"+\"test_loss.npy\")\n",
    "exact_001_a4anorm = np.load(\"exact_001_a4a\"+\"norm.npy\")\n",
    "exact_001_a4atrain_accuracy  = np.load(\"exact_001_a4a\"+\"train_accuracy.npy\")\n",
    "exact_001_a4atest_accuracy  = np.load(\"exact_001_a4a\"+\"test_accuracy.npy\")\n",
    "exact_001_a4astepsizes = np.load(\"exact_001_a4a\"+\"stepsizes.npy\")\n",
    "\n",
    "print(\"Final test accuracy : \", exact_001_a4atest_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", exact_001_a4atrain_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", exact_001_a4anorm[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_0005train_loss = np.load(\"exact_0005\"+\"train_loss.npy\")\n",
    "exact_0005test_loss = np.load(\"exact_0005\"+\"test_loss.npy\")\n",
    "exact_0005norm = np.load(\"exact_0005\"+\"norm.npy\")\n",
    "exact_0005train_accuracy  = np.load(\"exact_0005\"+\"train_accuracy.npy\")\n",
    "exact_0005test_accuracy  = np.load(\"exact_0005\"+\"test_accuracy.npy\")\n",
    "exact_0005stepsizes = np.load(\"exact_0005\"+\"stepsizes.npy\")\n",
    "\n",
    "print(\"Final test accuracy : \", exact_0005test_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", exact_0005train_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", exact_0005norm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_0005_a4atrain_loss = np.load(\"exact_0005_a4a\"+\"train_loss.npy\")\n",
    "exact_0005_a4atest_loss = np.load(\"exact_0005_a4a\"+\"test_loss.npy\")\n",
    "exact_0005_a4anorm = np.load(\"exact_0005_a4a\"+\"norm.npy\")\n",
    "exact_0005_a4atrain_accuracy  = np.load(\"exact_0005_a4a\"+\"train_accuracy.npy\")\n",
    "exact_0005_a4atest_accuracy  = np.load(\"exact_0005_a4a\"+\"test_accuracy.npy\")\n",
    "exact_0005_a4astepsizes = np.load(\"exact_0005_a4a\"+\"stepsizes.npy\")\n",
    "\n",
    "print(\"Final test accuracy : \", exact_0005_a4atest_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", exact_0005_a4atrain_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", exact_0005_a4anorm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_001train_loss = np.load(\"periodic_001\"+\"train_loss.npy\")\n",
    "periodic_001test_loss = np.load(\"periodic_001\"+\"test_loss.npy\")\n",
    "periodic_001norm = np.load(\"periodic_001\"+\"norm.npy\")\n",
    "periodic_001train_accuracy  = np.load(\"periodic_001\"+\"train_accuracy.npy\")\n",
    "periodic_001test_accuracy  = np.load(\"periodic_001\"+\"test_accuracy.npy\")\n",
    "periodic_001stepsizes = np.load(\"periodic_001\"+\"stepsizes.npy\")\n",
    "\n",
    "periodic_001train_loss = [np.min(periodic_001train_loss[:i]) for i in range(1,len(periodic_001train_loss)+1)]\n",
    "periodic_001test_loss = [np.min(periodic_001test_loss[:i]) for i in range(1,len(periodic_001test_loss)+1)]\n",
    "periodic_001norm = [np.min(periodic_001norm[:i]) for i in range(1,len(periodic_001norm)+1)]\n",
    "\n",
    "print(\"Final test accuracy : \", periodic_001test_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", periodic_001train_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", periodic_001norm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_001_a4atrain_loss = np.load(\"periodic_001_a4a\"+\"train_loss.npy\")\n",
    "periodic_001_a4atest_loss = np.load(\"periodic_001_a4a\"+\"test_loss.npy\")\n",
    "periodic_001_a4anorm = np.load(\"periodic_001_a4a\"+\"norm.npy\")\n",
    "periodic_001_a4atrain_accuracy  = np.load(\"periodic_001_a4a\"+\"train_accuracy.npy\")\n",
    "periodic_001_a4atest_accuracy  = np.load(\"periodic_001_a4a\"+\"test_accuracy.npy\")\n",
    "periodic_001_a4astepsizes = np.load(\"periodic_001_a4a\"+\"stepsizes.npy\")\n",
    "\n",
    "periodic_001_a4atrain_loss = [np.min(periodic_001_a4atrain_loss[:i]) for i in range(1,len(periodic_001_a4atrain_loss)+1)]\n",
    "periodic_001_a4atest_loss = [np.min(periodic_001_a4atest_loss[:i]) for i in range(1,len(periodic_001_a4atest_loss)+1)]\n",
    "periodic_001_a4anorm = [np.min(periodic_001_a4anorm[:i]) for i in range(1,len(periodic_001_a4anorm)+1)]\n",
    "\n",
    "print(\"Final test accuracy : \", periodic_001_a4atest_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", periodic_001_a4atrain_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", periodic_001_a4anorm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_0005train_loss = np.load(\"periodic_0005\"+\"train_loss.npy\")\n",
    "periodic_0005test_loss = np.load(\"periodic_0005\"+\"test_loss.npy\")\n",
    "periodic_0005norm = np.load(\"periodic_0005\"+\"norm.npy\")\n",
    "periodic_0005train_accuracy  = np.load(\"periodic_0005\"+\"train_accuracy.npy\")\n",
    "periodic_0005test_accuracy  = np.load(\"periodic_0005\"+\"test_accuracy.npy\")\n",
    "periodic_0005stepsizes = np.load(\"periodic_0005\"+\"stepsizes.npy\")\n",
    "\n",
    "periodic_0005train_loss = [np.min(periodic_0005train_loss[:i]) for i in range(1,len(periodic_0005train_loss)+1)]\n",
    "periodic_0005test_loss = [np.min(periodic_0005test_loss[:i]) for i in range(1,len(periodic_0005test_loss)+1)]\n",
    "periodic_0005norm = [np.min(periodic_0005norm[:i]) for i in range(1,len(periodic_0005norm)+1)]\n",
    "\n",
    "print(\"Final test accuracy : \", periodic_0005test_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", periodic_0005train_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", periodic_0005norm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_0005_a4atrain_loss = np.load(\"periodic_0005_a4a\"+\"train_loss.npy\")\n",
    "periodic_0005_a4atest_loss = np.load(\"periodic_0005_a4a\"+\"test_loss.npy\")\n",
    "periodic_0005_a4anorm = np.load(\"periodic_0005_a4a\"+\"norm.npy\")\n",
    "periodic_0005_a4atrain_accuracy  = np.load(\"periodic_0005_a4a\"+\"train_accuracy.npy\")\n",
    "periodic_0005_a4atest_accuracy  = np.load(\"periodic_0005_a4a\"+\"test_accuracy.npy\")\n",
    "periodic_0005_a4astepsizes = np.load(\"periodic_0005_a4a\"+\"stepsizes.npy\")\n",
    "\n",
    "periodic_0005_a4atrain_loss = [np.min(periodic_0005_a4atrain_loss[:i]) for i in range(1,len(periodic_0005_a4atrain_loss)+1)]\n",
    "periodic_0005_a4atest_loss = [np.min(periodic_0005_a4atest_loss[:i]) for i in range(1,len(periodic_0005_a4atest_loss)+1)]\n",
    "periodic_0005_a4anorm = [np.min(periodic_0005_a4anorm[:i]) for i in range(1,len(periodic_0005_a4anorm)+1)]\n",
    "\n",
    "print(\"Final test accuracy : \", periodic_0005_a4atest_accuracy[-1])\n",
    "\n",
    "print(\"Final train loss : \", periodic_0005_a4atrain_loss[-1])\n",
    "\n",
    "print(\"Final norm: \", periodic_0005_a4anorm[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to create the figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_figure(algo_001,algo_005,gd_001,gd_005,gd_mean_001,gd_mean_005,name_algo,metric,savename): \n",
    "    # Create figure and subfigures\n",
    "    fig, axs = plt.subplots(1, 2,sharey=True, figsize=(12, 4))\n",
    "    # Plot on each subfigure\n",
    "    \n",
    "\n",
    "    axs[0].plot(gd_mean_001, label=\"{1.9,1.91,...,1.99}/L\", linestyle='--')\n",
    "    axs[0].fill_between(range(len(gd_mean_001)), np.max(gd_001,axis=0), np.min(gd_001, axis=0), alpha=0.2,color='orange')\n",
    "    axs[1].plot(gd_mean_005, label=\"{1.9,1.91,...,1.99}/L\", linestyle='--')\n",
    "    axs[1].fill_between(range(len(gd_mean_005)), np.max(gd_005,axis=0), np.min(gd_005, axis=0), alpha=0.2,color='orange')\n",
    "\n",
    "    axs[0].plot(algo_001, label=name_algo)\n",
    "    axs[1].plot(algo_005, label=name_algo)\n",
    "\n",
    "    # Add titles to each subplot\n",
    "    axs[0].set_title(\"Stop at norm < 0.01\",fontsize=12)\n",
    "    axs[1].set_title(\"Stop at norm < 0.005\",fontsize=12)\n",
    "    #axs.set_title(\"Stop at norm < 0.0005\",fontsize=12)\n",
    "    # Add titles and legends\n",
    "    for ax in axs:\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    # Add axis labels\n",
    "    axs[0].set_ylabel(metric, fontsize=14)\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"Iterations\", fontsize=14)\n",
    "    # Set overall figure title\n",
    "    fig.suptitle(metric+\" vs Iterations\", fontsize=16,y=1.05)\n",
    "    #plt.savefig(\"Figures/Dynamic/train_loss_vs_dynamics.pdf\",bbox_inches='tight')\n",
    "    if savename!=None:\n",
    "        plt.savefig(savename,bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_figure_gd(gd_001_1,gd_001_15,gd_001_2,gd_0005_1,gd_0005_15,gd_0005_2,metric,savename):\n",
    "\n",
    "    max_iter_001 = max(len(gd_001_1), len(gd_001_15), len(gd_001_2))\n",
    "    max_iter_0005 = max(len(gd_0005_1), len(gd_0005_15), len(gd_0005_2))\n",
    "    # Create figure and subfigures\n",
    "    fig, axs = plt.subplots(1, 2,sharey=True, figsize=(12, 4))\n",
    "    # Plot on each subfigure\n",
    "    color= [\"green\",\"orange\",\"blue\"]\n",
    "\n",
    "    len_1 = len(gd_001_1)\n",
    "    axs[0].plot(gd_001_1, color=color[0],label=\"1/L\")\n",
    "    final = [gd_001_1[-1] for _ in range(max_iter_001 - len_1)]\n",
    "\n",
    "    len_15 = len(gd_001_15)\n",
    "    axs[0].plot(gd_001_15, color=color[1],label=\"1.5/L\")\n",
    "    final = [gd_001_15[-1] for _ in range(max_iter_001 - len_15)]\n",
    "\n",
    "    len_2 = len(gd_001_2)\n",
    "    axs[0].plot(gd_001_2, color=color[2],label=\"1.9/L\")\n",
    "    final = [gd_001_2[-1] for _ in range(max_iter_001 - len_2)]\n",
    "\n",
    "    len_1 = len(gd_0005_1)\n",
    "    axs[1].plot(gd_0005_1, color=color[0],label=\"1/L\")\n",
    "    final = [gd_0005_1[-1] for _ in range(max_iter_0005 - len_1)]\n",
    "\n",
    "    len_15 = len(gd_0005_15)\n",
    "    axs[1].plot(gd_0005_15, color=color[1],label=\"1.5/L\")\n",
    "    final = [gd_0005_15[-1] for _ in range(max_iter_0005 - len_15)]\n",
    "\n",
    "    len_2 = len(gd_0005_2)\n",
    "    axs[1].plot(gd_0005_2, color=color[2],label=\"1.9/L\")\n",
    "    final = [gd_0005_2[-1] for _ in range(max_iter_0005 - len_2)]\n",
    "\n",
    "    # Add titles to each subplot\n",
    "    axs[0].set_title(\"Stop at norm < 0.01\",fontsize=12)\n",
    "    axs[1].set_title(\"Stop at norm < 0.005\",fontsize=12)\n",
    "    #axs[2].set_title(\"Stop at norm < 0.0005\",fontsize=12)\n",
    "    # Add titles and legends\n",
    "    for ax in axs:\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    # Add axis labels\n",
    "    axs[0].set_ylabel(metric,fontsize=14)\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"Iterations\",fontsize=14)\n",
    "    # Set overall figure title\n",
    "    fig.suptitle(metric+\" vs Iterations\", fontsize=16,y=1.05)\n",
    "    if savename != None:\n",
    "        plt.savefig(savename,bbox_inches='tight') \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Figures for constant learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_figure_gd(gd_001train_loss_1,gd_001train_loss_15,gd_001train_loss_2,gd_0005train_loss_1,gd_0005train_loss_15,gd_0005train_loss_2,\"Train Loss\",\"Figures/GD/train_loss_iteration.pdf\")\n",
    "create_figure_gd(gd_001test_loss_1,gd_001test_loss_15,gd_001test_loss_2,gd_0005test_loss_1,gd_0005test_loss_15,gd_0005test_loss_2,\"Test Loss\",None)\n",
    "create_figure_gd(gd_001norm_1,gd_001norm_15,gd_001norm_2,gd_0005norm_1,gd_0005norm_15,gd_0005norm_2,\"Norm\",\"Figures/GD/norm_iteration.pdf\")\n",
    "create_figure_gd(gd_001train_accuracy_1,gd_001train_accuracy_15,gd_001train_accuracy_2,gd_0005train_accuracy_1,gd_0005train_accuracy_15,gd_0005train_accuracy_2,\"Train Accuracy\",None)\n",
    "create_figure_gd(gd_001test_accuracy_1,gd_001test_accuracy_15,gd_001test_accuracy_2,gd_0005test_accuracy_1,gd_0005test_accuracy_15,gd_0005test_accuracy_2,\"Test Accuracy\",\"Figures/GD/test_accuracy_iteration.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_figure_gd(gd_001_a4atrain_loss_1,gd_001_a4atrain_loss_15,gd_001_a4atrain_loss_2,gd_0005_a4atrain_loss_1,gd_0005_a4atrain_loss_15,gd_0005_a4atrain_loss_2,\"Train Loss\",\"Figures/GD/train_loss_a4a_iteration.pdf\")\n",
    "create_figure_gd(gd_001_a4atest_loss_1,gd_001_a4atest_loss_15,gd_001_a4atest_loss_2,gd_0005_a4atest_loss_1,gd_0005_a4atest_loss_15,gd_0005_a4atest_loss_2,\"Test Loss\",None)\n",
    "create_figure_gd(gd_001_a4anorm_1,gd_001_a4anorm_15,gd_001_a4anorm_2,gd_0005_a4anorm_1,gd_0005_a4anorm_15,gd_0005_a4anorm_2,\"Norm\",\"Figures/GD/norm_a4a_iteration.pdf\")\n",
    "create_figure_gd(gd_001_a4atrain_accuracy_1,gd_001_a4atrain_accuracy_15,gd_001_a4atrain_accuracy_2,gd_0005_a4atrain_accuracy_1,gd_0005_a4atrain_accuracy_15,gd_0005_a4atrain_accuracy_2,\"Train Accuracy\",None)\n",
    "create_figure_gd(gd_001_a4atest_accuracy_1,gd_001_a4atest_accuracy_15,gd_001_a4atest_accuracy_2,gd_0005_a4atest_accuracy_1,gd_0005_a4atest_accuracy_15,gd_0005_a4atest_accuracy_2,\"Test Accuracy\",\"Figures/GD/test_accuracy_a4a_iteration.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Figure for dynamic step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_figure(dynamic_001train_loss,dynamic_0005train_loss,gd_mean_001train_loss,gd_mean_0005train_loss,train_loss_mean_001,train_loss_mean_0005,\"Dynamic\",\"Train Loss\",\"Figures/Dynamic/train_loss.pdf\")\n",
    "create_figure(dynamic_001test_loss,dynamic_0005test_loss,gd_mean_001test_loss,gd_mean_0005test_loss,test_loss_mean_001,test_loss_mean_0005,\"Dynamic\",\"Test Loss\",None)\n",
    "create_figure(dynamic_001train_accuracy,dynamic_0005train_accuracy,gd_mean_001train_accuracy,gd_mean_0005train_accuracy,train_accuracy_mean_001,train_accuracy_mean_0005,\"Dynamic\",\"Train Accuracy\",None)\n",
    "create_figure(dynamic_001test_accuracy,dynamic_0005test_accuracy,gd_mean_001test_accuracy,gd_mean_0005test_accuracy,test_accuracy_mean_001,test_accuracy_mean_0005,\"Dynamic\",\"Test Accuracy\",\"Figures/Dynamic/test_accuracy.pdf\")\n",
    "create_figure(dynamic_001norm,dynamic_0005norm,gd_mean_001norm,gd_mean_0005norm,norm_mean_001,norm_mean_0005,\"Dynamic\",\"Norm\",\"Figures/Dynamic/norm.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_figure(dynamic_001_a4atrain_loss,dynamic_0005_a4atrain_loss,gd_mean_001_a4atrain_loss,gd_mean_0005_a4atrain_loss,train_loss_mean_001_a4a,train_loss_mean_0005_a4a,\"Dynamic\",\"Train Loss\",\"Figures/Dynamic/train_loss_a4a.pdf\")\n",
    "create_figure(dynamic_001_a4atest_loss,dynamic_0005_a4atest_loss,gd_mean_001_a4atest_loss,gd_mean_0005_a4atest_loss,test_loss_mean_001_a4a,test_loss_mean_0005_a4a,\"Dynamic\",\"Test Loss\",None)\n",
    "create_figure(dynamic_001_a4atrain_accuracy,dynamic_0005_a4atrain_accuracy,gd_mean_001_a4atrain_accuracy,gd_mean_0005_a4atrain_accuracy,train_accuracy_mean_001_a4a,train_accuracy_mean_0005_a4a,\"Dynamic\",\"Train Accuracy\",None)\n",
    "create_figure(dynamic_001_a4atest_accuracy,dynamic_0005_a4atest_accuracy,gd_mean_001_a4atest_accuracy,gd_mean_0005_a4atest_accuracy,test_accuracy_mean_001_a4a,test_accuracy_mean_0005_a4a,\"Dynamic\",\"Test Accuracy\",\"Figures/Dynamic/test_accuracy_a4a.pdf\")\n",
    "create_figure(dynamic_001_a4anorm,dynamic_0005_a4anorm,gd_mean_001_a4anorm,gd_mean_0005_a4anorm,norm_mean_001_a4a,norm_mean_0005_a4a,\"Dynamic\",\"Norm\",\"Figures/Dynamic/norm_a4a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Figure for optimal step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_figure(optimal_001train_loss,optimal_0005train_loss,gd_mean_001train_loss,gd_mean_0005train_loss,train_loss_mean_001,train_loss_mean_0005,\"optimal\",\"Train Loss\",\"Figures/Optimal/train_loss.pdf\")\n",
    "create_figure(optimal_001test_loss,optimal_0005test_loss,gd_mean_001test_loss,gd_mean_0005test_loss,test_loss_mean_001,test_loss_mean_0005,\"optimal\",\"Test Loss\",None)\n",
    "create_figure(optimal_001train_accuracy,optimal_0005train_accuracy,gd_mean_001train_accuracy,gd_mean_0005train_accuracy,train_accuracy_mean_001,train_accuracy_mean_0005,\"optimal\",\"Train Accuracy\",None)\n",
    "create_figure(optimal_001test_accuracy,optimal_0005test_accuracy,gd_mean_001test_accuracy,gd_mean_0005test_accuracy,test_accuracy_mean_001,test_accuracy_mean_0005,\"optimal\",\"Test Accuracy\",\"Figures/Optimal/test_accuracy.pdf\")\n",
    "create_figure(optimal_001norm,optimal_0005norm,gd_mean_001norm,gd_mean_0005norm,norm_mean_001,norm_mean_0005,\"optimal\",\"Norm\",\"Figures/Optimal/norm.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_figure(optimal_001_a4atrain_loss,optimal_0005_a4atrain_loss,gd_mean_001_a4atrain_loss,gd_mean_0005_a4atrain_loss,train_loss_mean_001_a4a,train_loss_mean_0005_a4a,\"optimal\",\"Train Loss\",\"Figures/Optimal/train_loss_a4a.pdf\")\n",
    "create_figure(optimal_001_a4atest_loss,optimal_0005_a4atest_loss,gd_mean_001_a4atest_loss,gd_mean_0005_a4atest_loss,test_loss_mean_001_a4a,test_loss_mean_0005_a4a,\"optimal\",\"Test Loss\",None)\n",
    "create_figure(optimal_001_a4atrain_accuracy,optimal_0005_a4atrain_accuracy,gd_mean_001_a4atrain_accuracy,gd_mean_0005_a4atrain_accuracy,train_accuracy_mean_001_a4a,train_accuracy_mean_0005_a4a,\"optimal\",\"Train Accuracy\",None)\n",
    "create_figure(optimal_001_a4atest_accuracy,optimal_0005_a4atest_accuracy,gd_mean_001_a4atest_accuracy,gd_mean_0005_a4atest_accuracy,test_accuracy_mean_001_a4a,test_accuracy_mean_0005_a4a,\"optimal\",\"Test Accuracy\",\"Figures/Optimal/test_accuracy_a4a.pdf\")\n",
    "create_figure(optimal_001_a4anorm,optimal_0005_a4anorm,gd_mean_001_a4anorm,gd_mean_0005_a4anorm,norm_mean_001_a4a,norm_mean_0005_a4a,\"optimal\",\"Norm\",\"Figures/Optimal/norm_a4a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Figure for exact step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_figure(exact_001train_loss,exact_0005train_loss,gd_mean_001train_loss,gd_mean_0005train_loss,train_loss_mean_001,train_loss_mean_0005,\"exact\",\"Train Loss\",\"Figures/Exact/train_loss.pdf\")\n",
    "create_figure(exact_001test_loss,exact_0005test_loss,gd_mean_001test_loss,gd_mean_0005test_loss,test_loss_mean_001,test_loss_mean_0005,\"exact\",\"Test Loss\",None)\n",
    "create_figure(exact_001train_accuracy,exact_0005train_accuracy,gd_mean_001train_accuracy,gd_mean_0005train_accuracy,train_accuracy_mean_001,train_accuracy_mean_0005,\"exact\",\"Train Accuracy\",None)\n",
    "create_figure(exact_001test_accuracy,exact_0005test_accuracy,gd_mean_001test_accuracy,gd_mean_0005test_accuracy,test_accuracy_mean_001,test_accuracy_mean_0005,\"exact\",\"Test Accuracy\",\"Figures/Exact/test_accuracy.pdf\")\n",
    "create_figure(exact_001norm,exact_0005norm,gd_mean_001norm,gd_mean_0005norm,norm_mean_001,norm_mean_0005,\"exact\",\"Norm\",\"Figures/Exact/norm.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_figure(exact_001_a4atrain_loss,exact_0005_a4atrain_loss,gd_mean_001_a4atrain_loss,gd_mean_0005_a4atrain_loss,train_loss_mean_001_a4a,train_loss_mean_0005_a4a,\"exact\",\"Train Loss\",\"Figures/Exact/train_loss_a4a.pdf\")\n",
    "create_figure(exact_001_a4atest_loss,exact_0005_a4atest_loss,gd_mean_001_a4atest_loss,gd_mean_0005_a4atest_loss,test_loss_mean_001_a4a,test_loss_mean_0005_a4a,\"exact\",\"Test Loss\",None)\n",
    "create_figure(exact_001_a4atrain_accuracy,exact_0005_a4atrain_accuracy,gd_mean_001_a4atrain_accuracy,gd_mean_0005_a4atrain_accuracy,train_accuracy_mean_001_a4a,train_accuracy_mean_0005_a4a,\"exact\",\"Train Accuracy\",None)\n",
    "create_figure(exact_001_a4atest_accuracy,exact_0005_a4atest_accuracy,gd_mean_001_a4atest_accuracy,gd_mean_0005_a4atest_accuracy,test_accuracy_mean_001_a4a,test_accuracy_mean_0005_a4a,\"exact\",\"Test Accuracy\",\"Figures/Exact/test_accuracy_a4a.pdf\")\n",
    "create_figure(exact_001_a4anorm,exact_0005_a4anorm,gd_mean_001_a4anorm,gd_mean_0005_a4anorm,norm_mean_001_a4a,norm_mean_0005_a4a,\"exact\",\"Norm\",\"Figures/Exact/norm_a4a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Figure for periodic step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_figure(periodic_001train_loss,periodic_0005train_loss,gd_mean_001train_loss,gd_mean_0005train_loss,train_loss_mean_001,train_loss_mean_0005,\"periodic\",\"Train Loss\",\"Figures/Periodic/train_loss.pdf\")\n",
    "create_figure(periodic_001test_loss,periodic_0005test_loss,gd_mean_001test_loss,gd_mean_0005test_loss,test_loss_mean_001,test_loss_mean_0005,\"periodic\",\"Test Loss\",None)\n",
    "create_figure(periodic_001train_accuracy,periodic_0005train_accuracy,gd_mean_001train_accuracy,gd_mean_0005train_accuracy,train_accuracy_mean_001,train_accuracy_mean_0005,\"periodic\",\"Train Accuracy\",None)\n",
    "create_figure(periodic_001test_accuracy,periodic_0005test_accuracy,gd_mean_001test_accuracy,gd_mean_0005test_accuracy,test_accuracy_mean_001,test_accuracy_mean_0005,\"periodic\",\"Test Accuracy\",\"Figures/Periodic/test_accuracy.pdf\")\n",
    "create_figure(periodic_001norm,periodic_0005norm,gd_mean_001norm,gd_mean_0005norm,norm_mean_001,norm_mean_0005,\"periodic\",\"Norm\",\"Figures/Periodic/norm.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_figure(periodic_001_a4atrain_loss,periodic_0005_a4atrain_loss,gd_mean_001_a4atrain_loss,gd_mean_0005_a4atrain_loss,train_loss_mean_001_a4a,train_loss_mean_0005_a4a,\"periodic\",\"Train Loss\",\"Figures/Periodic/train_loss_a4a.pdf\")\n",
    "create_figure(periodic_001_a4atest_loss,periodic_0005_a4atest_loss,gd_mean_001_a4atest_loss,gd_mean_0005_a4atest_loss,test_loss_mean_001_a4a,test_loss_mean_0005_a4a,\"periodic\",\"Test Loss\",None)\n",
    "create_figure(periodic_001_a4atrain_accuracy,periodic_0005_a4atrain_accuracy,gd_mean_001_a4atrain_accuracy,gd_mean_0005_a4atrain_accuracy,train_accuracy_mean_001_a4a,train_accuracy_mean_0005_a4a,\"periodic\",\"Train Accuracy\",None)\n",
    "create_figure(periodic_001_a4atest_accuracy,periodic_0005_a4atest_accuracy,gd_mean_001_a4atest_accuracy,gd_mean_0005_a4atest_accuracy,test_accuracy_mean_001_a4a,test_accuracy_mean_0005_a4a,\"periodic\",\"Test Accuracy\",\"Figures/Periodic/test_accuracy_a4a.pdf\")\n",
    "create_figure(periodic_001_a4anorm,periodic_0005_a4anorm,gd_mean_001_a4anorm,gd_mean_0005_a4anorm,norm_mean_001_a4a,norm_mean_0005_a4a,\"periodic\",\"Norm\",\"Figures/Periodic/norm_a4a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Figure for comparisons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and subfigures\n",
    "fig, axs = plt.subplots(1, 2,sharey=True, figsize=(12, 4))\n",
    "# Plot on each subfigure\n",
    "axs[0].plot(train_loss_mean_001, label=\"{1.9,1.91,...,1.99}/L\", linestyle='--')\n",
    "axs[0].fill_between(range(len(train_loss_mean_001)), np.max(gd_mean_001train_loss,axis=0), np.min(gd_mean_001train_loss, axis=0), alpha=0.2)\n",
    "axs[1].plot(train_loss_mean_0005, label=\"{1.9,1.91,...,1.99}/L\", linestyle='--')\n",
    "axs[1].fill_between(range(len(train_loss_mean_0005)), np.max(gd_mean_0005train_loss,axis=0), np.min(gd_mean_0005train_loss, axis=0), alpha=0.2)\n",
    "\n",
    "axs[0].plot(optimal_001train_loss, label=\"Optimal\")\n",
    "axs[1].plot(optimal_0005train_loss, label=\"Optimal\")\n",
    "\n",
    "axs[0].plot(exact_001train_loss, label=\"Exact\")\n",
    "axs[1].plot(exact_0005train_loss, label=\"Exact\")\n",
    "\n",
    "axs[0].plot(dynamic_001train_loss, label=\"Dynamic\")\n",
    "axs[1].plot(dynamic_0005train_loss, label=\"Dynamic\")\n",
    "\n",
    "axs[0].plot(periodic_001train_loss, label=\"Periodic\")\n",
    "axs[1].plot(periodic_0005train_loss, label=\"Periodic\")\n",
    "\n",
    "\n",
    "# Add titles to each subplot\n",
    "axs[0].set_title(\"Stop at norm < 0.01\",fontsize=12)\n",
    "axs[1].set_title(\"Stop at norm < 0.005\",fontsize=12)\n",
    "#axs.set_title(\"Stop at norm < 0.0005\",fontsize=12)\n",
    "\n",
    "metric = \"Train Loss\"\n",
    "# Add titles and legends\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "# Add axis labels\n",
    "axs[0].set_ylabel(metric)\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"Iterations\")\n",
    "# Set overall figure title\n",
    "fig.suptitle(metric+\" vs Iterations\", fontsize=16,y=1.05)\n",
    "plt.savefig(\"Figures/train_loss.pdf\",bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create figure and subfigures\n",
    "fig, axs = plt.subplots(1, 2,sharey=True, figsize=(12, 4))\n",
    "# Plot on each subfigure\n",
    "axs[0].plot(norm_mean_001, label=\"{1.9,1.91,...,1.99}/L\", linestyle='--')\n",
    "axs[0].fill_between(range(len(norm_mean_001)), np.max(gd_mean_001norm,axis=0), np.min(gd_mean_001norm, axis=0), alpha=0.2)\n",
    "axs[1].plot(norm_mean_0005, label=\"{1.9,1.91,...,1.99}/L\", linestyle='--')\n",
    "axs[1].fill_between(range(len(norm_mean_0005)), np.max(gd_mean_0005norm,axis=0), np.min(gd_mean_0005norm, axis=0), alpha=0.2)\n",
    "\n",
    "axs[0].plot(optimal_001norm, label=\"Optimal\")\n",
    "axs[1].plot(optimal_0005norm, label=\"Optimal\")\n",
    "\n",
    "axs[0].plot(exact_001norm, label=\"Exact\")\n",
    "axs[1].plot(exact_0005norm, label=\"Exact\")\n",
    "\n",
    "axs[0].plot(dynamic_001norm, label=\"Dynamic\")\n",
    "axs[1].plot(dynamic_0005norm, label=\"Dynamic\")\n",
    "\n",
    "axs[0].plot(periodic_001norm, label=\"Periodic\")\n",
    "axs[1].plot(periodic_0005norm, label=\"Periodic\")\n",
    "\n",
    "\n",
    "\n",
    "# Add titles to each subplot\n",
    "axs[0].set_title(\"Stop at norm < 0.01\",fontsize=12)\n",
    "axs[1].set_title(\"Stop at norm < 0.005\",fontsize=12)\n",
    "#axs.set_title(\"Stop at norm < 0.0005\",fontsize=12)\n",
    "\n",
    "metric = \"Norm\"\n",
    "# Add titles and legends\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "# Add axis labels\n",
    "axs[0].set_ylabel(metric)\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"Iterations\")\n",
    "# Set overall figure title\n",
    "fig.suptitle(metric+\" vs Iterations\", fontsize=16,y=1.05)\n",
    "plt.savefig(\"Figures/norm.pdf\",bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create figure and subfigures\n",
    "fig, axs = plt.subplots(1, 2,sharey=True, figsize=(12, 4))\n",
    "# Plot on each subfigure\n",
    "axs[0].plot(test_accuracy_mean_001, label=\"{1.9,1.91,...,1.99}/L\", linestyle='--')\n",
    "axs[0].fill_between(range(len(test_accuracy_mean_001)), np.max(gd_mean_001test_accuracy,axis=0), np.min(gd_mean_001test_accuracy, axis=0), alpha=0.2)\n",
    "axs[1].plot(test_accuracy_mean_0005, label=\"{1.9,1.91,...,1.99}/L\", linestyle='--')\n",
    "axs[1].fill_between(range(len(test_accuracy_mean_0005)), np.max(gd_mean_0005test_accuracy,axis=0), np.min(gd_mean_0005test_accuracy, axis=0), alpha=0.2)\n",
    "\n",
    "\n",
    "axs[0].plot(optimal_001test_accuracy, label=\"Optimal\")\n",
    "axs[1].plot(optimal_0005test_accuracy, label=\"Optimal\")\n",
    "\n",
    "axs[0].plot(exact_001test_accuracy, label=\"Exact\")\n",
    "axs[1].plot(exact_0005test_accuracy, label=\"Exact\")\n",
    "\n",
    "axs[0].plot(dynamic_001test_accuracy, label=\"Dynamic\")\n",
    "axs[1].plot(dynamic_0005test_accuracy, label=\"Dynamic\")\n",
    "\n",
    "axs[0].plot(periodic_001test_accuracy, label=\"Periodic\")\n",
    "axs[1].plot(periodic_0005test_accuracy, label=\"Periodic\")\n",
    "\n",
    "\n",
    "# Add titles to each subplot\n",
    "axs[0].set_title(\"Stop at test_accuracy < 0.01\",fontsize=12)\n",
    "axs[1].set_title(\"Stop at test_accuracy < 0.005\",fontsize=12)\n",
    "#axs.set_title(\"Stop at test_accuracy < 0.0005\",fontsize=12)\n",
    "\n",
    "metric = \"test accuracy\"\n",
    "# Add titles and legends\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "# Add axis labels\n",
    "axs[0].set_ylabel(metric)\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"Iterations\")\n",
    "# Set overall figure title\n",
    "fig.suptitle(metric+\" vs Iterations\", fontsize=16,y=1.05)\n",
    "plt.savefig(\"Figures/test_accuracy.pdf\",bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create figure and subfigures\n",
    "fig, axs = plt.subplots(1, 2,sharey=True, figsize=(12, 4))\n",
    "# Plot on each subfigure\n",
    "axs[0].plot(train_loss_mean_001_a4a, label=\"{1.9,1.91,...,1.99}/L\", linestyle='--')\n",
    "axs[0].fill_between(range(len(train_loss_mean_001_a4a)), np.max(gd_mean_001_a4atrain_loss,axis=0), np.min(gd_mean_001_a4atrain_loss, axis=0), alpha=0.2)\n",
    "axs[1].plot(train_loss_mean_0005_a4a, label=\"{1.9,1.91,...,1.99}/L\", linestyle='--')\n",
    "axs[1].fill_between(range(len(train_loss_mean_0005_a4a)), np.max(gd_mean_0005_a4atrain_loss,axis=0), np.min(gd_mean_0005_a4atrain_loss, axis=0), alpha=0.2)\n",
    "\n",
    "axs[0].plot(optimal_001_a4atrain_loss, label=\"Optimal\")\n",
    "axs[1].plot(optimal_0005_a4atrain_loss, label=\"Optimal\")\n",
    "\n",
    "axs[0].plot(exact_001_a4atrain_loss, label=\"Exact\")\n",
    "axs[1].plot(exact_0005_a4atrain_loss, label=\"Exact\")\n",
    "\n",
    "axs[0].plot(dynamic_001_a4atrain_loss, label=\"Dynamic\")\n",
    "axs[1].plot(dynamic_0005_a4atrain_loss, label=\"Dynamic\")\n",
    "\n",
    "axs[0].plot(periodic_001_a4atrain_loss, label=\"Periodic\")\n",
    "axs[1].plot(periodic_0005_a4atrain_loss, label=\"Periodic\")\n",
    "\n",
    "\n",
    "\n",
    "# Add titles to each subplot\n",
    "axs[0].set_title(\"Stop at norm < 0.01\",fontsize=12)\n",
    "axs[1].set_title(\"Stop at norm < 0.005\",fontsize=12)\n",
    "#axs.set_title(\"Stop at norm < 0.0005\",fontsize=12)\n",
    "\n",
    "metric = \"Train Loss\"\n",
    "# Add titles and legends\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "# Add axis labels\n",
    "axs[0].set_ylabel(metric)\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"Iterations\")\n",
    "# Set overall figure title\n",
    "fig.suptitle(metric+\" vs Iterations\", fontsize=16,y=1.05)\n",
    "plt.savefig(\"Figures/train_loss_a4a.pdf\",bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create figure and subfigures\n",
    "fig, axs = plt.subplots(1, 2,sharey=True, figsize=(12, 4))\n",
    "# Plot on each subfigure\n",
    "axs[0].plot(norm_mean_001_a4a, label=\"{1.9,1.91,...,1.99}/L\", linestyle='--')\n",
    "axs[0].fill_between(range(len(norm_mean_001_a4a)), np.max(gd_mean_001_a4anorm,axis=0), np.min(gd_mean_001_a4anorm, axis=0), alpha=0.2)\n",
    "axs[1].plot(norm_mean_0005_a4a, label=\"{1.9,1.91,...,1.99}/L\", linestyle='--')\n",
    "axs[1].fill_between(range(len(norm_mean_0005_a4a)), np.max(gd_mean_0005_a4anorm,axis=0), np.min(gd_mean_0005_a4anorm, axis=0), alpha=0.2)\n",
    "\n",
    "axs[0].plot(optimal_001_a4anorm, label=\"Optimal\")\n",
    "axs[1].plot(optimal_0005_a4anorm, label=\"Optimal\")\n",
    "\n",
    "axs[0].plot(exact_001_a4anorm, label=\"Exact\")\n",
    "axs[1].plot(exact_0005_a4anorm, label=\"Exact\")\n",
    "\n",
    "axs[0].plot(dynamic_001_a4anorm, label=\"Dynamic\")\n",
    "axs[1].plot(dynamic_0005_a4anorm, label=\"Dynamic\")\n",
    "\n",
    "axs[0].plot(periodic_001_a4anorm, label=\"Periodic\")\n",
    "axs[1].plot(periodic_0005_a4anorm, label=\"Periodic\")\n",
    "\n",
    "# Add titles to each subplot\n",
    "axs[0].set_title(\"Stop at norm < 0.01\",fontsize=12)\n",
    "axs[1].set_title(\"Stop at norm < 0.005\",fontsize=12)\n",
    "#axs.set_title(\"Stop at norm < 0.0005\",fontsize=12)\n",
    "\n",
    "metric = \"Norm\"\n",
    "# Add titles and legends\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "# Add axis labels\n",
    "axs[0].set_ylabel(metric)\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"Iterations\")\n",
    "# Set overall figure title\n",
    "fig.suptitle(metric+\" vs Iterations\", fontsize=16,y=1.05)\n",
    "plt.savefig(\"Figures/norm_a4a.pdf\",bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create figure and subfigures\n",
    "fig, axs = plt.subplots(1, 2,sharey=True, figsize=(12, 4))\n",
    "# Plot on each subfigure\n",
    "axs[0].plot(test_accuracy_mean_001_a4a, label=\"{1.9,1.91,...,1.99}/L\", linestyle='--')\n",
    "axs[0].fill_between(range(len(test_accuracy_mean_001_a4a)), np.max(gd_mean_001_a4atest_accuracy,axis=0), np.min(gd_mean_001_a4atest_accuracy, axis=0), alpha=0.2)\n",
    "axs[1].plot(test_accuracy_mean_0005_a4a, label=\"{1.9,1.91,...,1.99}/L\", linestyle='--')\n",
    "axs[1].fill_between(range(len(test_accuracy_mean_0005_a4a)), np.max(gd_mean_0005_a4atest_accuracy,axis=0), np.min(gd_mean_0005_a4atest_accuracy, axis=0), alpha=0.2)\n",
    "\n",
    "axs[0].plot(optimal_001_a4atest_accuracy, label=\"Optimal\")\n",
    "axs[1].plot(optimal_0005_a4atest_accuracy, label=\"Optimal\")\n",
    "\n",
    "axs[0].plot(exact_001_a4atest_accuracy, label=\"Exact\")\n",
    "axs[1].plot(exact_0005_a4atest_accuracy, label=\"Exact\")\n",
    "\n",
    "axs[0].plot(dynamic_001_a4atest_accuracy, label=\"Dynamic\")\n",
    "axs[1].plot(dynamic_0005_a4atest_accuracy, label=\"Dynamic\")\n",
    "\n",
    "axs[0].plot(periodic_001_a4atest_accuracy, label=\"Periodic\")\n",
    "axs[1].plot(periodic_0005_a4atest_accuracy, label=\"Periodic\")\n",
    "\n",
    "\n",
    "# Add titles to each subplot\n",
    "axs[0].set_title(\"Stop at test_accuracy < 0.01\",fontsize=12)\n",
    "axs[1].set_title(\"Stop at test_accuracy < 0.005\",fontsize=12)\n",
    "#axs.set_title(\"Stop at test_accuracy < 0.0005\",fontsize=12)\n",
    "\n",
    "metric = \"test accuracy\"\n",
    "\n",
    "# Add titles and legends\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "# Add axis labels\n",
    "axs[0].set_ylabel(metric)\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"Iterations\")\n",
    "# Set overall figure title\n",
    "fig.suptitle(metric+\" vs Iterations\", fontsize=16,y=1.05)\n",
    "plt.savefig(\"Figures/test_accuracy_a4a.pdf\",bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
