{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a4a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modele import Modele\n",
    "from Optimiseur import Optimiseur\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "X_train_, y_train = load_svmlight_file(\"a4a.txt\")\n",
    "print(\"X_train.shape:\", X_train_.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_, y_test = load_svmlight_file(\"a4a_t.Txt\")\n",
    "X_test_ = X_test_[:,:-1]\n",
    "print(\"X_test.shape:\", X_test_.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dense = X_train_.toarray()  \n",
    "X_test_dense = X_test_.toarray()\n",
    "\n",
    "X_train = X_train_dense.reshape(-1, 122) \n",
    "X_test = X_test_dense.reshape(-1, 122)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = [1e-5,1e-4,1e-3,1e-2,1e-1,1,1e1,1e2,1e3,1e4,1e5]\n",
    "alphas = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "for gamma in gammas:\n",
    "    modele = Modele(0,gamma)\n",
    "    alpha = modele.alpha_opt(X_train,y_train,gamma)\n",
    "    alphas.append(alpha)\n",
    "    train_loss.append(modele.loss_function(X_train,y_train,alpha))\n",
    "    train_accuracy.append(modele.accuracy(X_train,X_train,y_train,alpha))\n",
    "    test_accuracy.append(modele.accuracy(X_train,X_test,y_test,alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test = np.where(test_accuracy == np.max(test_accuracy))[0]\n",
    "best_train = np.where(train_accuracy == np.max(train_accuracy))[0]\n",
    "\n",
    "print(\"best gamma range for train: \", [gammas[i] for i in best_train])\n",
    "print(\"best gamma range for test: \", [gammas[i] for i in best_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(gammas, test_accuracy)\n",
    "plt.plot(gammas, test_accuracy, label='Test accuracy')\n",
    "plt.xlabel('Parameter Gamma (log scale)')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Test Accuracy for different parameter gamma')\n",
    "plt.savefig('accuracy_rbf_a4a.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(gammas,train_loss)\n",
    "plt.plot(gammas, train_loss, label='Train loss')\n",
    "plt.xlabel('Parameter Gamma (log scale)')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Train loss (log scale)')\n",
    "plt.title('Train loss for different parameter gamma')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas_2 = np.linspace(0.10,1,30)\n",
    "alphas_2 = []\n",
    "train_loss_2 = []\n",
    "train_accuracy_2 = []\n",
    "test_accuracy_2 = []\n",
    "\n",
    "for gamma in gammas_2:\n",
    "    modele = Modele(0,gamma)\n",
    "    alpha = modele.alpha_opt(X_train,y_train,gamma)\n",
    "    alphas_2.append(alpha)\n",
    "    train_loss_2.append(modele.loss_function(X_train,y_train,alpha))\n",
    "    train_accuracy_2.append(modele.accuracy(X_train,X_train,y_train,alpha))\n",
    "    test_accuracy_2.append(modele.accuracy(X_train,X_test,y_test,alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test = np.where(test_accuracy_2 == np.max(test_accuracy_2))[0]\n",
    "best_train = np.where(train_accuracy_2 == np.max(train_accuracy_2))[0]\n",
    "\n",
    "print(\"best gamma range for train: \", [gammas_2[i] for i in best_train])\n",
    "print(\"best gamma range for test: \", [gammas_2[i] for i in best_test])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(gammas_2, test_accuracy_2)\n",
    "plt.plot(gammas_2, test_accuracy_2, label='Test accuracy')\n",
    "plt.xlabel('Parameter Gamma')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Test Accuracy for different parameter gamma')\n",
    "plt.savefig('accuracy_rbf_2_a4a.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(gammas_2,train_loss_2)\n",
    "plt.plot(gammas_2, train_loss_2, label='Train loss')\n",
    "plt.xlabel('Parameter Gamma (log scale)')\n",
    "\n",
    "plt.ylabel('Train loss (log scale)')\n",
    "plt.title('Train loss for different parameter gamma')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"gamma chosen:\",0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create figure to compare the test accuracy vs learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele = Modele(0,0.6)\n",
    "optimiseur = Optimiseur(modele)\n",
    "L,mu = modele.constante_L(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters=5000\n",
    "target=0.05\n",
    "criterion='norm'\n",
    "\n",
    "n_lr= 20\n",
    "nb_init = 10\n",
    "\n",
    "train_loss_001_2k = np.zeros((n_lr,nb_init))\n",
    "test_loss_001_2k = np.zeros((n_lr,nb_init))\n",
    "norm_001_2k = np.zeros((n_lr,nb_init))\n",
    "train_accuracy_001_2k = np.zeros((n_lr,nb_init))\n",
    "test_accuracy_001_2k = np.zeros((n_lr,nb_init))\n",
    "nb_ite_001_2k = np.zeros((n_lr,nb_init))\n",
    "\n",
    "for i in range(nb_init):\n",
    "    init= np.random.randn(X_train.shape[0]) \n",
    "\n",
    "    L_001_2k,mu = modele.constante_L(X_train)\n",
    "    learning_rates = np.linspace(1/L_001_2k,1.99/L_001_2k,n_lr)\n",
    "\n",
    "    j=0\n",
    "    alphas=[]\n",
    "    for lr in learning_rates:\n",
    "        alpha, alpha_list = optimiseur.gradient_descent(X_train, y_train, init.copy(),lr, max_iters, target, criterion)\n",
    "        alphas.append(alpha)\n",
    "        nb_ite_001_2k[j,i] = len(alpha_list)\n",
    "        j+=1\n",
    "    train_loss, test_loss, norm, train_accuracy, test_accuracy = modele.compute_all(X_train, X_test,y_train, y_test,alphas)\n",
    "    train_loss_001_2k[:,i] = train_loss\n",
    "    test_loss_001_2k[:,i] = test_loss\n",
    "    norm_001_2k[:,i] = norm\n",
    "    train_accuracy_001_2k[:,i] = train_accuracy\n",
    "    test_accuracy_001_2k[:,i] = test_accuracy\n",
    "        \n",
    "\n",
    "print(\"dimensions alphas: (n_lr,nb_init,X_train.shape[0])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = np.linspace(1,1.99,n_lr)\n",
    "\n",
    "print(nb_ite_001_2k)\n",
    "\n",
    "test_loss_mean = np.mean(test_loss_001_2k[:,:6], axis=1)\n",
    "test_loss_std = np.std(test_loss_001_2k[:,:6], axis=1)\n",
    "train_loss_mean = np.mean(train_loss_001_2k[:,:6], axis=1)\n",
    "train_loss_std = np.std(train_loss_001_2k[:,:6], axis=1)\n",
    "norm_mean = np.mean(norm_001_2k[:,:6], axis=1)\n",
    "norm_std = np.std(norm_001_2k[:,:6], axis=1)\n",
    "train_accuracy_mean = np.mean(train_accuracy_001_2k[:,:6], axis=1)\n",
    "train_accuracy_std = np.std(train_accuracy_001_2k[:,:6], axis=1)\n",
    "test_accuracy_mean = np.mean(test_accuracy_001_2k[:,:6], axis=1)\n",
    "test_accuracy_std = np.std(test_accuracy_001_2k[:,:6], axis=1)\n",
    "\n",
    "ts = np.linspace(1,1.99,n_lr)\n",
    "\n",
    "plt.figure()\n",
    "#plt.scatter(ts, test_accuracy_mean, label='Test Accuracy')\n",
    "plt.plot(ts, test_accuracy_mean)\n",
    "plt.fill_between(ts, test_accuracy_mean - test_accuracy_std, test_accuracy_mean + test_accuracy_std, alpha=0.2)\n",
    "plt.xlabel('Learning Rate * L')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Test Accuracy vs Learning Rate')\n",
    "#plt.legend()\n",
    "#plt.savefig('Figures/GD/test_accuracy_a4a_001.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
